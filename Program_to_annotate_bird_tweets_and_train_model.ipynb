{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2DcJ8jGzS-mb"
      ],
      "authorship_tag": "ABX9TyOSnmkdiOC5gzGQAtHOHOMf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahaanirbannew/birdname-ner-nlp-demo/blob/main/Program_to_annotate_bird_tweets_and_train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installs, Imports, Function Definitions\n"
      ],
      "metadata": {
        "id": "2DcJ8jGzS-mb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsrxrUioKaVW",
        "outputId": "b9fdfb90-67e4-40eb-efa2-3b6072303c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tweet-preprocessor\n",
            "  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ekphrasis\n",
            "  Downloading ekphrasis-0.5.4-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (4.64.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (3.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (3.7)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.21.6)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (5.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->ekphrasis) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->ekphrasis) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->ekphrasis) (1.15.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->ekphrasis) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->ekphrasis) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->ekphrasis) (7.1.2)\n",
            "Installing collected packages: ftfy, colorama, ekphrasis\n",
            "Successfully installed colorama-0.4.5 ekphrasis-0.5.4 ftfy-6.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.20.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 4.1 MB/s \n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.3 MB/s \n",
            "\u001b[?25hCollecting jarowinkler<2.0.0,>=1.2.0\n",
            "  Downloading jarowinkler-1.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 70.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: jarowinkler, rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.20.3 jarowinkler-1.2.1 rapidfuzz-2.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy[transformers] in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (21.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (3.0.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.21.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.4.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (3.0.7)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (4.1.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.9.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.0.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.11.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (3.3.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (8.1.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (0.10.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (0.6.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (0.4.2)\n",
            "Collecting spacy-transformers<1.2.0,>=1.1.2\n",
            "  Downloading spacy_transformers-1.1.8-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy[transformers]) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy[transformers]) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy[transformers]) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (2.10)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (1.12.1+cu113)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2\n",
            "  Downloading spacy_alignments-0.8.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 7.7 MB/s \n",
            "\u001b[?25hCollecting transformers<4.22.0,>=3.4.0\n",
            "  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 53.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy[transformers]) (0.7.8)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 36.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 75.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy[transformers]) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy[transformers]) (2.0.1)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, spacy-alignments, spacy-transformers\n",
            "Successfully installed huggingface-hub-0.9.1 spacy-alignments-0.8.5 spacy-transformers-1.1.8 tokenizers-0.12.1 transformers-4.21.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.0/en_core_web_lg-3.4.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 587.7 MB 9.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (21.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-trf==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.4.0/en_core_web_trf-3.4.0-py3-none-any.whl (460.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 460.3 MB 36 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy-transformers<1.2.0,>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from en-core-web-trf==3.4.0) (1.1.8)\n",
            "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-trf==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.0) (0.8.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: transformers<4.22.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.0) (4.21.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.0) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.0) (0.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.0) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.0) (3.8.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.0) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.0) (4.12.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-trf==3.4.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-trf\n",
            "Successfully installed en-core-web-trf-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n"
          ]
        }
      ],
      "source": [
        "!pip install tweet-preprocessor\n",
        "!pip install ekphrasis\n",
        "!pip install Levenshtein  \n",
        "!python -m spacy download en_core_web_sm \n",
        "!pip install spacy[transformers]\n",
        "!python -m spacy download en_core_web_lg \n",
        "!python -m spacy download en_core_web_trf "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pickle \n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "import re\n",
        "import tweepy\n",
        "import preprocessor as p\n",
        "p.set_options(p.OPT.EMOJI, p.OPT.MENTION, p.OPT.URL, p.OPT.SMILEY, p.OPT.NUMBER, p.OPT.HASHTAG)\n",
        "from ekphrasis.classes.segmenter import Segmenter\n",
        "seg_tw = Segmenter(corpus=\"english\")\n",
        "import requests\n",
        "import csv\n",
        "import datetime \n",
        "from datetime import datetime \n",
        "import os, sys \n",
        "import pandas as pd  \n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "from spacy.util import filter_spans\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5Pk1usWQg4o",
        "outputId": "9e39b692-3411-483a-8c98-e90205003c00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word statistics files not found!\n",
            "Downloading... done!\n",
            "Unpacking... done!\n",
            "Reading english - 1grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/english/counts_1grams.txt\n",
            "Reading english - 2grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/english/counts_2grams.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spelling_corrections = {}\n",
        "spelling_corrections[\"grey\"] = \"gray\" \n",
        "spelling_corrections[\"pegion\"] = \"pigeon\" \n",
        "spelling_corrections[\"brested\"] = \"breasted\" \n",
        "spelling_corrections[\"serpant\"] = \"serpent\" \n",
        "spelling_corrections[\"avedavat\"] = \"avadavat\" \n",
        "spelling_corrections[\"open billed stork\"] = \"asian openbill\" \n",
        "spelling_corrections[\"secretary bird\"] = \"Secretarybird\" \n",
        "spelling_corrections[\"dollar bird\"] = \"dollarbird\"\n",
        "spelling_corrections[\"silver bill\"] = \"silverbill\"\n",
        "\n",
        "def create_twitter_app_obj():\n",
        "  consumer_key = \"iPaIdR8GRI59yTJMs0Es0dIBN\"\n",
        "  consumer_secret = \"pLadg3UaLeK3yKDujRMChRN3p8hUDBOjBsuOBy8j8ERr4zz1vs\"\n",
        "  access_token = \"39085479-AabHt6bmFSbClDfUZuHjModYPAxVlOxHeMA79UyVt\"\n",
        "  access_token_secret = \"3IqXDISfqg14wzMNNn2AX4KYG9Wfkltt21QxKasE4YNnG\"\n",
        "  # Creating the authentication object\n",
        "  auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "  # Setting your access token and secret\n",
        "  auth.set_access_token(access_token, access_token_secret)\n",
        "  # Creating the API object while passing in auth information\n",
        "\n",
        "  try:\n",
        "    api = tweepy.API(auth) \n",
        "    return api\n",
        "  except:\n",
        "    print(\"Error: Error making the Twitter Object.\")\n",
        "    return 0\n",
        "\n",
        "twitter = create_twitter_app_obj() \n",
        "\n",
        "def connect_to_google_drive():\n",
        "  drive.mount(\"/content/drive\", force_remount=False)\n",
        "connect_to_google_drive()\n",
        "\n",
        "def get_google_drive_folder_path():\n",
        "  path = \"/content/drive/My Drive/IndiAves/\" \n",
        "  return path \n",
        "google_drive_path= get_google_drive_folder_path() \n",
        "\n",
        "def get_eBird_commonNames_data(path):\n",
        "  file = open(path+\"bird_dict_comName\",'rb')\n",
        "  try:\n",
        "    eBird_commonNames_data = pickle.load(file)\n",
        "    return eBird_commonNames_data \n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "    return 0\n",
        "ebirds = get_eBird_commonNames_data(google_drive_path)\n",
        "\n",
        "def load_all_birds_list(path):\n",
        "  file = open(path+\"bird_list_df\",'rb')\n",
        "  bird_list_df = pickle.load(file)\n",
        "  try: \n",
        "    return bird_list_df\n",
        "  except:\n",
        "    print(\"Error: No bird list found.\")\n",
        "    return 0\n",
        "wikibirds = load_all_birds_list(google_drive_path) \n",
        "\n",
        "def basic_preprocess(tweet, spelling_corrections):\n",
        "  tweet = tweet.lower()\n",
        "  tweet = p.clean(tweet)\n",
        "  tweet = tweet.replace(\"\\n\",\" \")  \n",
        "  tweet = tweet.replace(\"\\\\n\",\" \") \n",
        "  if tweet[:2] == \"b'\": tweet = tweet[1:] \n",
        "  tweet = tweet.replace(\"'\",\"\")\n",
        "  tweet = tweet.replace(\"#\",\"\")\n",
        "  tweet = re.sub(r'[^\\w\\s]', ' ', tweet)\n",
        "  tweet = re.sub(r' x..', '', tweet)\n",
        "  tweet = re.sub(r' +', ' ', tweet) \n",
        "  tweet = tweet.replace(\"x9c\",\"\")\n",
        "  tweet = tweet.strip()\n",
        "  for key in spelling_corrections: \n",
        "    if tweet.find(key)>-1: \n",
        "      tweet = tweet.replace(key,spelling_corrections[key])\n",
        "  return tweet \n",
        "\n",
        "def add_words_to_bird_vocab(bird_name, list_, spelling_corrections): \n",
        "  words = basic_preprocess(bird_name,spelling_corrections).split(\" \")\n",
        "  for word in words:\n",
        "    if word not in list_:\n",
        "      list_.append(word)\n",
        "  return list_\n",
        "\n",
        "def add_birdnames_to_list(bird_name, list_, spelling_corrections): \n",
        "  bird_name__ = basic_preprocess(bird_name, spelling_corrections) \n",
        "  if bird_name__ not in list_: \n",
        "    list_.append(bird_name__) \n",
        "  return list_\n",
        "\n",
        "all_birds_list = [] \n",
        "birdnames_words = [] \n",
        "birdnames = wikibirds[\"bird_name\"].unique().tolist() \n",
        "for speciesTag in ebirds:\n",
        "  all_birds_list = add_birdnames_to_list(ebirds[speciesTag], all_birds_list, spelling_corrections)\n",
        "  birdnames_words = add_words_to_bird_vocab(ebirds[speciesTag], birdnames_words, spelling_corrections) \n",
        "for birdname in birdnames: \n",
        "  all_birds_list = add_birdnames_to_list(birdname, all_birds_list, spelling_corrections)\n",
        "  birdnames_words = add_words_to_bird_vocab(birdname, birdnames_words, spelling_corrections) \n",
        "\n",
        "def return_alt_word(word_,birdnames_words): \n",
        "  min_distance = 1000\n",
        "  if word_ not in birdnames_words: \n",
        "    for word in birdnames_words: \n",
        "      dist_ = levenshtein_distance(word_,word)\n",
        "      if dist_ < min_distance: \n",
        "        min_distance = dist_\n",
        "        word__ = word \n",
        "  else: \n",
        "    return word_  \n",
        "  return word__\n",
        "\n",
        "def return_alt_bird(word_,all_birds_list): \n",
        "  min_distance = 1000\n",
        "  if word_ not in all_birds_list: \n",
        "    for word in all_birds_list: \n",
        "      dist_ = levenshtein_distance(word_,word)\n",
        "      if dist_ < min_distance: \n",
        "        min_distance = dist_\n",
        "        word__ = word \n",
        "  else: \n",
        "    return word_  \n",
        "  return word__\n",
        "\n",
        "def try_removing_hashtags(text,all_birds_list,birdnames_words):\n",
        "  status = False \n",
        "  #print(text)\n",
        "  hashtags = re.findall(r\"#(\\w+)\", text) \n",
        "  for hashtag in hashtags:\n",
        "    segmented_ = seg_tw.segment(hashtag) \n",
        "    words = segmented_.split(\" \") #ekhane spelling mistake thakbe na. \n",
        "    #for word in words: #in case there is a spelling mistake. #works only when there is a spelling mistake\n",
        "      #segmented_ = segmented_.replace(word, return_alt_word(word,birdnames_words))\n",
        "    for bird in all_birds_list: #not an exact match, because people always do not write the full name.\n",
        "      if bird.find(segmented_) > -1: \n",
        "        text = text.replace(\"#\"+hashtag,segmented_)\n",
        "        status = True\n",
        "  return text\n",
        "\n",
        "def get_bird_names(tweet, birdnames_words):\n",
        "  api_url = \"https://bird-name-ner-nlp.herokuapp.com/ner?sent=\"+tweet\n",
        "  response = requests.get(api_url).json()\n",
        "  #print(\"NER\",response['bird-ner'])\n",
        "  #print(\"WIKI\",response['bird-wiki'])\n",
        "  #print(\"EBIRD\",response['bird-ebird'])\n",
        "  bird_list_= [] \n",
        "  for bird in response['bird-wiki']: \n",
        "    if bird not in bird_list_: \n",
        "      bird_list_.append(bird) \n",
        "  for bird in response['bird-ebird']: \n",
        "    if bird not in bird_list_: \n",
        "      bird_list_.append(bird) \n",
        "  \n",
        "  for bird in response['bird-ner']:\n",
        "    status_ = False \n",
        "    if bird not in bird_list_: \n",
        "      #check for spelling errors.\n",
        "      for word in bird.split(\" \"):\n",
        "        bird = bird.replace(word, return_alt_word(word,birdnames_words)) \n",
        "\n",
        "      if len(bird)>0:\n",
        "        for bird_ in bird_list_:\n",
        "          if bird_.find(bird) > -1: #if it is found, then no action.  \n",
        "            status_ = True #found \n",
        "            break\n",
        "        if status_ == False:\n",
        "          bird_list_.append(bird) \n",
        "  \n",
        "  return bird_list_\n",
        "\n",
        "def get_birds_given_text(tweet,all_birds_list, birdnames_words,spelling_corrections):\n",
        "  tweet = try_removing_hashtags(tweet,all_birds_list, birdnames_words) \n",
        "  tweet = basic_preprocess(tweet, spelling_corrections) \n",
        "  print(tweet)  #needed to confirm birds.\n",
        "  bird_list = get_bird_names(tweet, birdnames_words) \n",
        "  return bird_list "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59hZEYqJKfec",
        "outputId": "cb82cf0b-50ad-416f-c996-d8c255beee74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_since_id(path,search_word):\n",
        "  file = open(path+\"since_id\",'rb')\n",
        "  try:\n",
        "    since_id_data = pickle.load(file)\n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "    return 0\n",
        "  try: \n",
        "    since_id = since_id_data[search_word]\n",
        "    return since_id\n",
        "  except:\n",
        "    print(\"Info: This looks like a new search.\")\n",
        "    return 0\n",
        "\n",
        "\n",
        "def what_search_term():\n",
        "  search_term = \"indiAves\"        ## CHANGE THIS.  \n",
        "  return search_term\n",
        "\n",
        "def load_training_data(path):\n",
        "  try: \n",
        "    file = open(path+\"training_data\",'rb')\n",
        "    training_data = pickle.load(file)\n",
        "    return training_data\n",
        "  except:\n",
        "    print(\"Error: No training data found.\")\n",
        "    return 0\n",
        "\n",
        "def import_best_model(google_drive_folder_path):\n",
        "  shutil.copyfile(google_drive_folder_path+\"model-best.zip\", \"/content/model-best.zip\")\n",
        "\n",
        "def extract_model_best_from_archive():\n",
        "  file_name = \"/content/model-best.zip\"\n",
        "  with ZipFile(file_name, 'r') as zip:\n",
        "    zip.extractall(\"/content/model-best\")\n",
        "\n",
        "def load_best_model_from_archive(google_drive_folder_path):\n",
        "  import_best_model(google_drive_folder_path)\n",
        "  extract_model_best_from_archive()\n",
        "  nlp_ner = spacy.load(\"model-best\") \n",
        "  return True, nlp_ner\n",
        "\n",
        "def add_to_database(api, search_word, ext_path, since_id):\n",
        "  new_search = \"#\" +search_word + \" -filter:retweets\" \n",
        "  count = 0\n",
        "  csvFile = open(ext_path+search_word+'.csv', 'a')\n",
        "  csvFile2 = open('/content/temp_.csv', 'w') \n",
        "\n",
        "  csvWriter = csv.writer(csvFile)\n",
        "  csvWriter2 = csv.writer(csvFile2)\n",
        "\n",
        "  for tweet in tweepy.Cursor(api.search,q=new_search,count=100,\n",
        "                            lang=\"en\",\n",
        "                            since_id=since_id, tweet_mode=\"extended\").items(): \n",
        "    if tweet.id > since_id:\n",
        "      since_id = tweet.id\n",
        "    \n",
        "    media_url=\"\"\n",
        "    if tweet.entities.get('media', []): media_url = tweet.entities.get('media', [])[0]['media_url']\n",
        "\n",
        "    hashtags = []\n",
        "    for tag in tweet.entities[\"hashtags\"]:\n",
        "      hashtags.append(tag[\"text\"]) \n",
        "    \n",
        "    csvWriter.writerow([tweet.created_at, tweet.id, tweet.user.screen_name.encode('utf-8'), tweet.user.location.encode('utf-8'), tweet.full_text.encode('utf-8'), media_url, hashtags])\n",
        "    csvWriter2.writerow([tweet.created_at, tweet.id, tweet.user.screen_name.encode('utf-8'), tweet.user.location.encode('utf-8'), tweet.full_text.encode('utf-8'), media_url, hashtags])\n",
        "    count +=1\n",
        "  print(datetime.now(),count, \"tweets retrieved.\")\n",
        "  return since_id \n",
        "\n",
        "def get_training_data(new_tweets,all_birds_list, birdnames_words, spelling_corrections, training_data): \n",
        "  for tweet in new_tweets: \n",
        "    bird_list = get_birds_given_text(tweet,all_birds_list, birdnames_words, spelling_corrections)\n",
        "    print(bird_list)\n",
        "    confirmation = input(\"Is the bird list identified, complete? y|n : \")\n",
        "    if confirmation.lower() in [\"yes\", \"y\", \"ja\", \"ya\"]:\n",
        "      birds = bird_list \n",
        "    else: \n",
        "      birds = input(\"Please confirm all birds: \")\n",
        "      bird_list = birds.split(\",\")\n",
        "\n",
        "    if birds != \"-\" and len(bird_list)>0: \n",
        "      for bird in bird_list:\n",
        "        bird = bird.strip() \n",
        "        training_data[\"annotations\"].append({'text': tweet, 'entities': [(tweet.find(bird), tweet.find(bird)+len(bird), 'BIRDNAME')]})\n",
        "  return training_data\n",
        "\n",
        "def export_training_data(training_data,path):\n",
        "  filepath = open(path+\"training_data\",'wb') \n",
        "  pickle.dump(training_data, filepath)                     \n",
        "  filepath.close() \n",
        "  print(len(training_data[\"annotations\"]), \"records in training data.\")\n",
        "  print(\"training data is saved.\") \n",
        "\n",
        "def update_since_id(since_id, path,search_word):\n",
        "  filepath = open(path+\"since_id\",'rb')\n",
        "  since_id_data = pickle.load(filepath)\n",
        "  since_id_data[search_word]=since_id\n",
        "  filepath = open(path+\"since_id\",'wb') \n",
        "  pickle.dump(since_id_data, filepath)                     \n",
        "  filepath.close()\n",
        "\n",
        "def is_GPU_on():\n",
        "  if tf.test.gpu_device_name() == \"\": \n",
        "    return False\n",
        "  return True\n",
        "\n",
        "def create_doc_bin(training_data,nlp):\n",
        "  from spacy.tokens import DocBin\n",
        "  from tqdm import tqdm\n",
        "  from spacy.util import filter_spans\n",
        "  doc_bin = DocBin()\n",
        "  for training_example  in tqdm(training_data['annotations']): \n",
        "    text = training_example['text']\n",
        "    labels = training_example['entities']\n",
        "    doc = nlp.make_doc(text) \n",
        "    ents = []\n",
        "    for start, end, label in labels:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        #if span is None:\n",
        "        #    print(\"Skipping entity\")\n",
        "        #else:\n",
        "        #    ents.append(span)\n",
        "        if span is not None:\n",
        "          ents.append(span)\n",
        "    filtered_ents = filter_spans(ents)\n",
        "    doc.ents = filtered_ents \n",
        "    doc_bin.add(doc)\n",
        "  doc_bin.to_disk(\"training_data.spacy\") # save the docbin object\n",
        "\n",
        "def import_base_config_file(google_drive_folder_path):\n",
        "  shutil.copyfile(google_drive_folder_path+\"base_config.cfg\", \"/content/base_config.cfg\")\n",
        "\n",
        "def archive_best_model_in_google_drive(google_folder_path):\n",
        "  shutil.make_archive(google_folder_path+\"model-best\", 'zip', \"/content/model-best\")\n",
        "\n",
        "def train_model_():\n",
        "  !python -m spacy init fill-config base_config.cfg config.cfg\n",
        "  !python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy --gpu-id 0\n",
        "\n",
        "\n",
        "def train_model(training_data,google_drive_path): \n",
        "  nlp = spacy.blank(\"en\")\n",
        "  create_doc_bin(training_data,nlp)\n",
        "  import_base_config_file(google_drive_path)\n",
        "  train_model_()\n",
        "  archive_best_model_in_google_drive(google_drive_path) "
      ],
      "metadata": {
        "id": "axIUvPokP-nK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execute this once:"
      ],
      "metadata": {
        "id": "jETAFA4KiUgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_word = what_search_term()                              #gets the search term = IndiAves\n",
        "training_data = load_training_data(google_drive_path)"
      ],
      "metadata": {
        "id": "Wc_pH9kHKm-t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Annotates Data, Creates Training Data"
      ],
      "metadata": {
        "id": "nOisNf-GiWqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "since_id = get_since_id(google_drive_path,search_word)        #Gets the \"since_id\" to fetch newer tweets. \n",
        "since_id = add_to_database(twitter,search_word, google_drive_path, since_id)  #downloads latest tweets to database, updates since_id\n",
        "new_tweets_df = pd.read_csv(\"/content/temp_.csv\", names=[\"created_at\", \"tweet_id\", \"user\", \"location\", \"tweet\", \"media_url\", \"hashtags\"])\n",
        "new_tweets = new_tweets_df[\"tweet\"].tolist() #makes a list of the new tweets. \n",
        "training_data = get_training_data(new_tweets,all_birds_list, birdnames_words, spelling_corrections, training_data) #gets updated training data \n",
        "export_training_data(training_data,google_drive_path) #very very important.\n",
        "update_since_id(since_id,google_drive_path,search_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zMgiaVNTUBw",
        "outputId": "fb73dcd3-771d-4f7c-fc0d-ca7e34d221a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-22 05:05:19.260930 0 tweets retrieved.\n",
            "4480 records in training data.\n",
            "training data is saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trains the Model"
      ],
      "metadata": {
        "id": "KiYWUOjGiy7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_GPU_on_colab = is_GPU_on()\n",
        "print(\"is_GPU_on\",is_GPU_on_colab)\n",
        "if is_GPU_on_colab == True: \n",
        "  train_model(training_data,google_drive_path) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7ly9czehOj8",
        "outputId": "3731b096-60a5-4902-b566-da387a8aee58"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is_GPU_on True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4480/4480 [00:01<00:00, 4053.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-09-22 05:08:19,977] [INFO] Set up nlp object from config\n",
            "INFO:spacy:Set up nlp object from config\n",
            "[2022-09-22 05:08:19,987] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "INFO:spacy:Pipeline: ['tok2vec', 'ner']\n",
            "[2022-09-22 05:08:19,991] [INFO] Created vocabulary\n",
            "INFO:spacy:Created vocabulary\n",
            "[2022-09-22 05:08:19,992] [INFO] Finished initializing nlp object\n",
            "INFO:spacy:Finished initializing nlp object\n",
            "[2022-09-22 05:08:32,399] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "INFO:spacy:Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     41.00    0.66    0.67    0.65    0.01\n",
            "  0     200         98.74   2312.60   65.12   59.23   72.32    0.65\n",
            "  0     400         46.49   1096.60   77.75   79.66   75.92    0.78\n",
            "  1     600         51.85   1006.49   82.61   88.30   77.62    0.83\n",
            "  1     800         62.56   1061.67   86.99   82.73   91.71    0.87\n",
            "  2    1000        218.90    997.78   89.42   86.00   93.13    0.89\n",
            "  3    1200         84.76   1135.91   90.77   88.39   93.28    0.91\n",
            "  4    1400         88.88   1089.53   92.38   92.11   92.66    0.92\n",
            "  6    1600         99.96   1190.21   92.65   92.76   92.54    0.93\n",
            "  8    1800        123.38   1325.07   93.02   94.73   91.38    0.93\n",
            " 10    2000        117.00   1418.81   93.04   94.73   91.41    0.93\n",
            " 12    2200        151.32   1655.70   92.78   90.95   94.68    0.93\n",
            " 15    2400        170.28   1810.80   93.16   96.41   90.13    0.93\n",
            " 19    2600        133.30   1792.87   93.23   94.64   91.85    0.93\n",
            " 22    2800        138.06   1757.12   92.95   91.48   94.47    0.93\n",
            " 25    3000        137.34   1682.23   93.37   94.65   92.12    0.93\n",
            " 28    3200        126.07   1691.16   93.41   96.13   90.84    0.93\n",
            " 32    3400        139.82   1654.15   93.45   96.28   90.78    0.93\n",
            " 35    3600        146.16   1679.69   93.41   97.17   89.92    0.93\n",
            " 38    3800        128.65   1596.42   93.28   96.41   90.34    0.93\n",
            " 41    4000        140.21   1624.20   93.11   97.84   88.82    0.93\n",
            " 45    4200        145.04   1623.00   93.26   97.60   89.30    0.93\n",
            " 48    4400        187.14   1614.19   93.54   95.25   91.88    0.94\n",
            " 51    4600        142.75   1584.48   93.45   97.30   89.89    0.93\n",
            " 54    4800        139.63   1580.07   93.47   95.30   91.71    0.93\n",
            " 58    5000        131.61   1575.59   93.47   92.09   94.89    0.93\n",
            " 61    5200        101.36   1526.00   93.46   94.15   92.78    0.93\n",
            " 64    5400        200.94   1549.43   93.43   97.88   89.36    0.93\n",
            " 67    5600        168.66   1611.24   93.39   95.70   91.20    0.93\n",
            " 70    5800        250.13   1556.48   93.63   92.41   94.89    0.94\n",
            " 74    6000        151.02   1555.04   93.61   93.56   93.67    0.94\n",
            " 77    6200        155.18   1515.89   93.56   93.39   93.73    0.94\n",
            " 80    6400        175.03   1537.97   93.56   91.79   95.39    0.94\n",
            " 83    6600        157.79   1557.72   93.45   94.01   92.90    0.93\n",
            " 87    6800        166.00   1526.77   93.56   91.15   96.11    0.94\n",
            " 90    7000        204.10   1528.31   93.57   95.77   91.47    0.94\n",
            " 93    7200        239.77   1549.94   93.55   93.26   93.85    0.94\n",
            " 96    7400        281.55   1546.57   93.35   98.07   89.06    0.93\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "model-last\n"
          ]
        }
      ]
    }
  ]
}